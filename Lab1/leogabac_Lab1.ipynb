{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/johanhoffman/DD2363_VT22/blob/leogabac-Lab1/leogabac_Lab1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RgtXlfYO_i7"
      },
      "source": [
        "# **Lab 01: Introduction**\n",
        "**Leonardo Gabriel Alanis Cant√∫**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9x_J5FVuPzbm"
      },
      "source": [
        "# **Abstract**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6UFTSzW7P8kL"
      },
      "source": [
        "Linear Algebra is a fundamental tool in Computer Science, its main objects of study are vectors and linear transformations. The most commonly used vectors are the elements of $\\mathbb{R}^n$, which are represented as lists of numbers usually written in the form of column array; on the other side, the most common way of representing linear transformations is by using matrices. \n",
        "\n",
        "In this report, the most common operations for vectors, such as the scalar product, matrix-vector multiplication, and matrix-matrix multiplication are implemented in code. Additionally, the euclidean norm, and the euclidean distance between vectors are implemented as additional exercises. In the methods section, simple mathematical descriptions of the operations are given, and futher implemented in Python code using the default \"list\" object, and \"numpy\" arrays for the simplicity of handling indexing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OkT8J7uOWpT3"
      },
      "source": [
        "#**About the code**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmB2noTr1Oyo"
      },
      "source": [
        "A short statement on who is the author of the file, and if the code is distributed under a certain license. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Pdll1Xc9WP0e",
        "outputId": "c952038b-67a9-400d-9987-ee0575bd159a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'KTH Royal Institute of Technology, Stockholm, Sweden.'"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "\"\"\"This program is a template for lab reports in the course\"\"\"\n",
        "\"\"\"DD2363 Methods in Scientific Computing, \"\"\"\n",
        "\"\"\"KTH Royal Institute of Technology, Stockholm, Sweden.\"\"\"\n",
        "\n",
        "# Copyright (C) 2020 Johan Hoffman (jhoffman@kth.se)\n",
        "\n",
        "# This file is part of the course DD2365 Advanced Computation in Fluid Mechanics\n",
        "# KTH Royal Institute of Technology, Stockholm, Sweden\n",
        "#\n",
        "# This is free software: you can redistribute it and/or modify\n",
        "# it under the terms of the GNU Lesser General Public License as published by\n",
        "# the Free Software Foundation, either version 3 of the License, or\n",
        "# (at your option) any later version.\n",
        "\n",
        "# This template is maintained by Johan Hoffman\n",
        "# Please report problems to jhoffman@kth.se"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28xLGz8JX3Hh"
      },
      "source": [
        "# **Set up environment**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2PYNusD08Wa"
      },
      "source": [
        "To have access to the neccessary modules you have to run this cell. If you need additional modules, this is where you add them. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Xw7VlErAX7NS"
      },
      "outputs": [],
      "source": [
        "# Load neccessary modules.\n",
        "# from google.colab import files\n",
        "\n",
        "import time\n",
        "import math\n",
        "import numpy as np\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib import tri\n",
        "from matplotlib import axes\n",
        "from mpl_toolkits.mplot3d import Axes3D"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnO3lhAigLev"
      },
      "source": [
        "# **Introduction**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5zMzgPlRAF6"
      },
      "source": [
        "Whithin the scope of this report, is the implementation of different operations regarding vectors and matrices in Python code, specifically the scalar product, matrix-vector and matrix-matrix products, euclidean norm and finally the euclidean distance.\n",
        "\n",
        "Let $v,w \\in  \\mathbb{R}^n$ be any two vectors with components $v_i,w_i$, then an inner product for this vector space is defined as follows\n",
        "\n",
        "$$\n",
        "(v,w) \\equiv v \\cdot w = \\sum_{i=1}^n v_i w_i,\n",
        "$$\n",
        "\n",
        "commonly known as the _scalar product_ between $v$ and $w$.\n",
        "\n",
        "Now, consider a linear transformation $T: \\mathbb{R}^n \\to \\mathbb{R}^m$ defined as the product $b = T(x) = Ax$ where $A$ is an $m\\times n$ matrix, the resulting vector is given as a linear combination of the columns of $A$ (also called components of $T$).\n",
        "\n",
        "$$\n",
        "b = x_1A_{1:} + \\cdots + x_nA_{n:}\n",
        "$$\n",
        "\n",
        "This is the so called _matrix-vector product_. Note that here $A_{i:}$ denotes the $i$-th column of $A$, also written as $Ae_{i}$ (see Lang's Linear Algebra, Theorem 2.1). Projecting into the standard basis, the components $b_i = (e_i,b)$ are then\n",
        "\n",
        "$$\n",
        "b_i = \\sum_{j=1}^n A_{ij}x_j.\n",
        "$$\n",
        "\n",
        "Which is an easier formula to implement in code. Now consider two matrices $A$ and $B$, then the _matrix-matrix_ product $C=AB$ is given by\n",
        "\n",
        "$$\n",
        "C_{ij} = \\sum_{k=1}^n A_{ik}B_{kj}.\n",
        "$$\n",
        "\n",
        "Noting that $A$ is $m \\times n$, $B$ is $n \\times p$, and the resulting matrix $C$ is $m \\times p$.\n",
        "\n",
        "Finally, for the n-th dimensional Euclidean space, the inner product induces a notion of _length_, from which we can take the so-called $\\ell^2$ norm, or well the _Euclidean-norm_ as\n",
        "\n",
        "$$\n",
        "\\| x \\| = \\sqrt{(x,x)} = \\left(  \\sum_{i=1}^n x_i^2\\right)^{1/2}.\n",
        "$$\n",
        "\n",
        "Using the Euclidean norm. we define the distance between thwo vectors $v,w\\in  \\mathbb{R}^n$ as\n",
        "\n",
        "$$\n",
        "\\text{distance}(v,w) = \\| v - w\\|\n",
        "$$\n",
        "\n",
        "In this Lab report, the previous algorithms will be implemented in Python code by using default lists and the numpy arrays objects for means of indexing simplification."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOQvukXZq5U5"
      },
      "source": [
        "# **Method**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "FkYYsNzxxJIT"
      },
      "outputs": [],
      "source": [
        "def inner_product(x,y):\n",
        "    # x is a vector of n elements\n",
        "    # y is a vector of n elements\n",
        "    \n",
        "    assert len(x)==len(y), \"Dimension error\"\n",
        "    \n",
        "    s = 0 # initialize\n",
        "    \n",
        "    for k in range(len(x)):\n",
        "        s += x[k]*y[k]\n",
        "    \n",
        "    return s\n",
        "\n",
        "def matrix_vector(A,x):\n",
        "    # A is a list of lists (or np array) with m rows and n columns\n",
        "    # x is a vector of n elements\n",
        "    \n",
        "    # the assertion error will come from the inner product*\n",
        "    \n",
        "    b = [0 for k in range(len(A))] # initialize\n",
        "    \n",
        "    for k in range(len(A)): # loop number of rows\n",
        "        b[k] = inner_product(A[k],x)\n",
        "        \n",
        "    return b\n",
        "\n",
        "def matrix_matrix(A,B):\n",
        "    # A is an np array of size (m,n)\n",
        "    # B is an np array of size (n,p)\n",
        "    \n",
        "    assert A.shape[1] == B.shape[0], \"Dimension mismatch\"\n",
        "    \n",
        "    C = np.zeros( (A.shape[0], B.shape[1]) ) \n",
        "    \n",
        "    for row in range(C.shape[0]):\n",
        "        for col in range(C.shape[1]):\n",
        "            for k in range(C.shape[1]):\n",
        "                C[row,col] += A[row,k]*B[k,col] \n",
        "    \n",
        "    return C\n",
        "\n",
        "def euclidean_norm(x):\n",
        "    norm2 = 0 # initialize\n",
        "    \n",
        "    for element in x:\n",
        "        norm2 += element**2\n",
        "    \n",
        "    return math.sqrt(norm2)\n",
        "\n",
        "def euclidean_distance(x,y):\n",
        "    dis2 = 0 # initialize\n",
        "    \n",
        "    for (xi,yi) in zip(x,y):\n",
        "        dis2 += (xi - yi)**2\n",
        "        \n",
        "    return math.sqrt(dis2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsQLT38gVbn_"
      },
      "source": [
        "# **Results**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4jJmc6BxJIU"
      },
      "source": [
        "The first test is on inner products, here we will perform the inner product of various vectors in different dimensions with known results such that we can test accuracy.\n",
        "\n",
        "First, for the following vector, we should expect a unitary norm.\n",
        "$$\n",
        "x = \\dfrac{1}{\\sqrt{2}}(1,1)^{\\text{T}} \\Rightarrow (x,x) = 1\n",
        "$$\n",
        "Similarly, we can check for orthogonality using the following two vectors\n",
        "$$\n",
        "x = (1,1,0)^{\\text{T}}, y = (0,0,3)^{\\text{T}} \\Rightarrow (x,y) = 0\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dfst34s-xJIV",
        "outputId": "a541cf27-2104-4bec-a618-7558c66979f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(x1,x1) =  0.9999999999999998\n",
            "Relative error: 2.220446049250313e-16\n",
            "(x2,y2) =  0.0\n",
            "Relative difference: 0.0\n"
          ]
        }
      ],
      "source": [
        "x1 = 1/math.sqrt(2)*np.array([1,1]) # (x1,x1) should get 1\n",
        "ip1 = inner_product(x1,x1)\n",
        "epsilon1 = abs( (1-ip1)/1 )\n",
        "print(\"(x1,x1) = \", ip1 )\n",
        "print(\"Relative error:\",epsilon1)\n",
        "\n",
        "x2 = [1,1,0]\n",
        "y2 = [0,0,3.7]\n",
        "ip2 = inner_product(x2,y2)\n",
        "print(\"(x2,y2) = \", ip2 )\n",
        "print(\"Relative difference:\", abs(0 - ip2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_M9WGbyxJIV"
      },
      "source": [
        "Secondly, we will perform some known transformations to vectors in $\\mathbb{R}^2$ and $\\mathbb{R}^3$, specifically a $\\pi/2$ counterclockwise rotation\n",
        "\n",
        "$$\n",
        "R(\\pi/2) = \\begin{pmatrix}\n",
        "0&-1 \\\\ 1&0\n",
        "\\end{pmatrix}\n",
        "$$\n",
        "then it should follow that $(R(\\pi/2)x,x) = 0$ by orthogonality.\n",
        "\n",
        "A reflection on the $xy$ plane should only flip the third component of any vector.\n",
        "$$\n",
        "R_{xy} = \\begin{pmatrix}\n",
        "1&0&0 \\\\ 0&1&0 \\\\ 0&0&-1 \n",
        "\\end{pmatrix}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GyTeY4jaxJIW",
        "outputId": "ca992e45-fa26-4f57-a16f-55ac0dc28237"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(R*x1, x1) =  0.0\n",
            "Relative difference: 0.0\n",
            "A2*x2 =  [2.0, 3.5, -6.0]\n"
          ]
        }
      ],
      "source": [
        "x1 = [2,3.5]\n",
        "A1 = [[0,-1], [1,0]] \n",
        "ip1 = inner_product(  matrix_vector(A1,x1), x1 )\n",
        "print( \"(R*x1, x1) = \", ip1 )\n",
        "print(\"Relative difference:\", abs(0 - ip1))\n",
        "\n",
        "x2 = [2,3.5,6]\n",
        "A2 = [[1,0,0], [0,1,0], [0,0,-1]] \n",
        "A2x2 = matrix_vector(A2,x2)\n",
        "print( \"A2*x2 = \", A2x2  )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yecaqjIRxJIW"
      },
      "source": [
        "Then we will test the matrix-matrix product by using the following two matrices and the exact result."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aaOF-VvPxJIX"
      },
      "source": [
        "$$\n",
        "AB = \\begin{pmatrix}\n",
        "1&3&5&6&3\\\\ 5&3&34&1&-3\\\\ 2.4&4.6&4&3&2\\\\ 0&0&0&3.5&1\\\\ 0&0&0&0&0\n",
        "\\end{pmatrix}\n",
        "\\begin{pmatrix}\n",
        "0&3&5&6&3\\\\ 5&0&3.4&1&-3\\\\ 2&4&0&3&2\\\\ 0&0&0&0&1\\\\ 0&0&0&0&0\n",
        "\\end{pmatrix} =\n",
        "\\begin{pmatrix}\n",
        "25&23&15.2&24&10\\\\ 83&151&35.2&135&75\\\\ 31&23.2&27.64&31&4.4\\\\0&0&0&0&3.5\\\\ 0&0&0&0&0\n",
        "\\end{pmatrix}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cROY5Z0VxJIX",
        "outputId": "51c5cbfb-b2d0-4a8a-c25f-768ced6c5d7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Relative difference:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00],\n",
              "       [ 0.00000000e+00,  0.00000000e+00, -3.55271368e-15,\n",
              "         0.00000000e+00,  0.00000000e+00],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "A = np.array( [ [1,3,5,6,3], [5,3,34,1,-3], [2.4,4.6,4,3,2], [0,0,0,3.5,1], [0,0,0,0,0] ] )\n",
        "B = np.array( [ [0,3,5,6,3], [5,0,3.4,1,-3], [2,4,0,3,2], [0,0,0,0,1], [0,0,0,0,0] ] )\n",
        "C = matrix_matrix(A,B)\n",
        "print(\"Relative difference:\")\n",
        "np.dot(A,B) - C"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICcSXw8PxJIY"
      },
      "source": [
        "Now, we are going to compute the norm of different vectors with their exact answer.\n",
        "$$\n",
        "x = (0,0,0,0,0,0,1)^{\\text{T}} \\Rightarrow \\| x \\| = 1\n",
        "$$\n",
        "\n",
        "$$\n",
        "x = (1,1)^{\\text{T}} \\Rightarrow \\| x \\| = \\sqrt{2}\n",
        "$$\n",
        "\n",
        "$$\n",
        "x = (1,2,3,4,5)^{\\text{T}} \\Rightarrow \\| x \\| = \\sqrt{55}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVZ2swfFxJIY",
        "outputId": "797f0b6a-1aed-49c1-d2fe-fb8701df51e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|x1| =  1.0\n",
            "Relative error: 0.0\n",
            "|x2| =  1.4142135623730951\n",
            "Relative error: 0.0\n",
            "|x3| =  7.416198487095663\n",
            "Relative error: 0.0\n"
          ]
        }
      ],
      "source": [
        "x1 = [0,0,0,0,0,0,1]\n",
        "x2 = [1,1]\n",
        "x3 = [1,2,3,4,5]\n",
        "\n",
        "en1 = euclidean_norm(x1)\n",
        "epsilon1 = abs( (1- en1)/1  )\n",
        "\n",
        "en2 = euclidean_norm(x2)\n",
        "epsilon2 = abs( (math.sqrt(2)- en2)/math.sqrt(1)  )\n",
        "\n",
        "en3 = euclidean_norm(x3)\n",
        "epsilon3 = abs( (math.sqrt(55)- en3)/math.sqrt(55)  )\n",
        "\n",
        "print(\"|x1| = \", en1 )\n",
        "print(\"Relative error:\",epsilon1)\n",
        "print(\"|x2| = \", en2 )\n",
        "print(\"Relative error:\",epsilon2)\n",
        "print(\"|x3| = \", en3 )\n",
        "print(\"Relative error:\",epsilon3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLJNGc7MxJIY"
      },
      "source": [
        "Finally, we are going to test the euclidean distance function. First we will compute the distance from the vector $(1,1,1,1,1)^\\text{T}$ to the origin $\\mathcal{O}$, since it must reproduce the results from the norm function, otherwise there is an error in the code.\n",
        "\n",
        "Then we will compute the distance between the following two vectors\n",
        "\n",
        "$$\n",
        "x = (1,2.3,3,2.3,4.5)^\\text{T}, y = (1,1,1,1,1)^\\text{T} \\Rightarrow \\text{distance}(x,y) = \\sqrt{19.63}\n",
        "$$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9FPOu_v2xJIZ",
        "outputId": "f6d1981f-d927-4488-e1bc-53adc11b39d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "d(x1,y1) = 2.23606797749979\n",
            "Relative error 0.0\n",
            "\n",
            "d(x2,y2) = 4.430575583375144\n",
            "Relative error = 0.0\n"
          ]
        }
      ],
      "source": [
        "x1 = [0,0,0,0,0]\n",
        "y1 = [1,1,1,1,1]\n",
        "# this should reproduce the norm\n",
        "ed1 = euclidean_distance(x1,y1)\n",
        "en1 = euclidean_norm(y1)\n",
        "print(\"d(x1,y1) =\", ed1 )\n",
        "epsilon1 = abs( (en1 - ed1)/en1 )\n",
        "print(\"Relative error\", epsilon1 )\n",
        "\n",
        "x2 = [1,2.3,3,2.3,4.5]\n",
        "y2 = [1,1,1,1,1]\n",
        "ed2 = euclidean_distance(x2,y2)\n",
        "epsilon2 = abs( ( math.sqrt(19.63) - ed2 )/math.sqrt(19.63) )\n",
        "\n",
        "print(\"\\nd(x2,y2) =\", ed2)\n",
        "print(\"Relative error =\", epsilon2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4GLBv0zWr7m"
      },
      "source": [
        "# **Discussion**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VeY_crwKxJIZ"
      },
      "source": [
        "Generally speaking, the results were favourable towards the implementations of the algorithms. To summarize, the implementations were fairly accurate since they only replicate exact mathematical definitions and formulas, hence the relative error between the correct answers, and the computed ones were mostly zero. Nevertheless, the few cases in which the results were \"not exact\" were mostly due to Floating Number rerpresentation of irrational numbers such as $\\sqrt{2}$ and other square roots.\n",
        "\n",
        "Since the algoritms are simple, the performance is fairly good as long as the dimensions of the vectors and matrices are not too big. These implementations are not well suited for cases in which we have to multiply matrices whose dimensions are in the order of hundreds of rows.\n",
        "\n",
        "As described in the introduction of this report, the implementations presented here are the foundation of many aplications that can be studied using Linear Algebra since every linear transformation can be mapped into a matrix, and evvery abstract vector can be mapped into a column vector by a chosen basis, hence the aplications of these algorithms go far beyond the scope of this report. "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "leogabac_Lab1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}