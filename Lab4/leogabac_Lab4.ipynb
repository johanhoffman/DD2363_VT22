{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/johanhoffman/DD2363_VT22/blob/leogabac-Lab4/Lab4/leogabac_Lab4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RgtXlfYO_i7"
      },
      "source": [
        "# **Lab 4: Approximation methods**\n",
        "**Leonardo Gabriel Alanis Cant√∫**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9x_J5FVuPzbm"
      },
      "source": [
        "# **Abstract**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6UFTSzW7P8kL"
      },
      "source": [
        "In this report we will take a look at local polynomial interpolation of a function. The goal is to implement in code the fundamental ideas, and test it. The results were good pretty much everywhere, except for the left enpoint. The reasons for this behaviour is unknown, but there are some untested hypothesis that will be discussed in the last section. Additionally, this code was implemented specifically for one test function, the reasoning behind this decision, and its generalization of this case will also be discussed properly in the last section."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Pdll1Xc9WP0e",
        "outputId": "e5abed00-3ff2-4f05-9df3-31c4919a1c2c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'KTH Royal Institute of Technology, Stockholm, Sweden.'"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "\"\"\"This program is a template for lab reports in the course\"\"\"\n",
        "\"\"\"DD2363 Methods in Scientific Computing, \"\"\"\n",
        "\"\"\"KTH Royal Institute of Technology, Stockholm, Sweden.\"\"\"\n",
        "\n",
        "# Copyright (C) 2020 Johan Hoffman (jhoffman@kth.se)\n",
        "\n",
        "# This file is part of the course DD2365 Advanced Computation in Fluid Mechanics\n",
        "# KTH Royal Institute of Technology, Stockholm, Sweden\n",
        "#\n",
        "# This is free software: you can redistribute it and/or modify\n",
        "# it under the terms of the GNU Lesser General Public License as published by\n",
        "# the Free Software Foundation, either version 3 of the License, or\n",
        "# (at your option) any later version.\n",
        "\n",
        "# This template is maintained by Johan Hoffman\n",
        "# Please report problems to jhoffman@kth.se"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28xLGz8JX3Hh"
      },
      "source": [
        "# **Set up environment**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2PYNusD08Wa"
      },
      "source": [
        "To have access to the neccessary modules you have to run this cell. If you need additional modules, this is where you add them. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Xw7VlErAX7NS"
      },
      "outputs": [],
      "source": [
        "# Load neccessary modules.\n",
        "from google.colab import files\n",
        "\n",
        "import time\n",
        "import numpy as np\n",
        "from math import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnO3lhAigLev"
      },
      "source": [
        "# **Introduction**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5zMzgPlRAF6"
      },
      "source": [
        "For a continuous fnction, the _polynomial interpolant_ in the  Lagrange basis is given by\n",
        "\n",
        "$$\n",
        "    \\pi_q f(x) = \\sum_{i=0}^q f(x_i)\\lambda(x), \\quad x \\in I,\n",
        "$$\n",
        "\n",
        "where the functions $\\lambda_i(x)$ are the so-called Lagrange polynomials. For a given _mesh_ $\\mathcal{T} = \\{ I_k \\}$ with subintervals $I_k = [ x_{k-1}, x_k ], ~ k = 1,\\ldots, m+1$ having $m$ internal nodes with not necessarily equal spacing $h_k$, we define the _local_ subinterval vector space as the interpolation of the nodes. The basis for this subspace, is given by the local linear Lagrange shape functions for the subinterval $I_k$.\n",
        "\n",
        "$$\n",
        "\\lambda_{k,0}(x) = \\dfrac{x_k-x}{h_k}, \\quad \\lambda_{k,1} = \\dfrac{x-x_{k-1}}{h_k},\n",
        "$$\n",
        "\n",
        "We want to express an interpolant in the global or local basis.\n",
        "\n",
        "$$\n",
        "v(x) = \\sum_{i=0}^{2(m+1)}\\alpha_i\\phi_i(x) = \\beta_{k,0}\\lambda_{k,0} + \\beta_{k,1}\\lambda_{k,1}.\n",
        "$$\n",
        "Since we want to \"connect the dots\", it is necessary to enforce continuity, this process puts constraints on the degrees of freedom with the mappings $\\alpha_k = \\beta_{k,1} = \\beta_{k+1,0}$ for the internal nodes, and $\\alpha_0 = \\beta_{1,0}$, and $\\alpha_{m+1} = \\beta_{m+1,1}$ for the endpoints, note that by doing this, we cut almost in half the amount of degrees of freedom.\n",
        "\n",
        "For the $L^2$ projection method, it will be of our particular interest to evaluate the polynomials of linear order on each subinterval $I_k$, hence $q=1$ for the implementation of Algorithm 9.1 in the course's textbook.\n",
        "\n",
        "The $L^2$ projection method relies on the Hilbert space of continuos square integrable functions on the interval $[a,b]$, equipped with the inner product.\n",
        "\n",
        "$$\n",
        "(f,g) = \\int_a^b f(x)g(x) \\text{ d}x,\n",
        "$$\n",
        "\n",
        "choosing a particular basis for the prohjection space, it follows that\n",
        "\n",
        "$$\n",
        "\\sum_{j = 1}^N \\alpha_j (\\phi_j,\\phi_i) = (f,\\phi_i),\n",
        "$$\n",
        "which is equivalent to a matrix equation\n",
        "$$\n",
        "a_{ij} = (\\phi_j,\\phi_i) = \\int_a^b \\phi_j(x)\\phi_i(x)\\text{ d}x,\\\\\n",
        "b_i = (f,\\phi_i) = \\int_a^b f(x) \\phi_i(x)\\text{ d}x,\n",
        "$$\n",
        "\n",
        "From the matrix equation we can compute teh coordinates $\\alpha_i$ to get the projection. If the basis supports local shape functions, then we can follow Algorithm 9.1 on the textbook to evaluate the local polynomials.\n",
        "\n",
        "In this particular work, I will focus on a particular working example(since there will be some computations made by hand), following the process of Example 9.8 in the textbook. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOQvukXZq5U5"
      },
      "source": [
        "# **Method**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zF4iBj5VURZx"
      },
      "source": [
        "Consider the function\n",
        "\n",
        "$$\n",
        "f(x) = \\cos \\left( \\dfrac{3 \\pi}{2}x\\right),\n",
        "$$\n",
        "\n",
        "which will be represented by\n",
        "\n",
        "$$\n",
        "P_h f(x) = \\sum_{j=0}^{m+1}\\alpha_j \\phi_j(x).\n",
        "$$\n",
        "\n",
        "Consider as well the equidistant mesh on the interval $[0,1]$ with spacing $h$. Then the matrix $A$ is a tri-diagonal sparse matrix of dimensions $(m+2)\\times (m+2)$ elements (Since the index $j= 0,1,2,\\ldots,m+1$). For $k = 1,\\ldots,m$ we will have the matrix elements\n",
        "\n",
        "$$\n",
        "a_{k,k} = \\dfrac{2h}{3}, \\quad a_{k,k+1} = a_{k,k-1} = \\dfrac{h}{6}.\n",
        "$$\n",
        "\n",
        "The load vector $b$ is computed as follows.\n",
        "$$\n",
        "b_k = \\int_0^1 f(x)\\phi_k(x) \\text{ d}x = \\int_{x_{k-1}}^{x_k} f(x)\\lambda_{k,1}(x) \\text{ d}x + \\int_{x_{k}}^{x_{k+1}} f(x)\\lambda_{k+1,0}(x) \\text{ d}x\n",
        "$$\n",
        "\n",
        "Recalling the definitions for $\\lambda_{k,j}$ we can perform these integrals (I made them with Wolfram Mathematica), to get\n",
        "\n",
        "$$\n",
        "b_k = \\dfrac{1}{9h\\pi^2}\\left[ 8\\cos(\\omega x_k) - 4\\cos(\\omega x_{k-1}) - 8\\cos(\\omega x_{k+1})\\right]\n",
        "$$\n",
        "\n",
        "There are some tricky things to do on the endpoints, there are several ways to include them:\n",
        "\n",
        "1. Include an 'virtual/auxiliary' intervals at the endopints that will be used for computation purposes.\n",
        "2. Use perdiodic boundary conditions (Which is what usually physicists do to ignore the boundaries).\n",
        "3. Ignore the problem and hope for the best.\n",
        "4. Go back to the integrals to treat the \"extra case\".\n",
        "\n",
        "The proper way to solve this is the fourth option. Following it properly will not change $A$, but the endpoints of the load vector will become (see example 9.7 on textbook p. 197)\n",
        "\n",
        "$$\n",
        "b_{0} = \\dfrac{1}{9h\\pi^2}\\left[ 8\\cos(\\omega x_{0}) - 4\\cos(\\omega x_{1}) - 6\\pi h\\sin(\\omega x_{0})\\right],\\\\\n",
        "b_{m+1} = \\dfrac{1}{9h\\pi^2}\\left[ 8\\cos(\\omega x_{m+1}) - 4\\cos(\\omega x_{m}) + 6\\pi h\\sin(\\omega x_{m+1})\\right].\n",
        "$$\n",
        "\n",
        "Again, there are \"missing terms\", as well as an \"extra term\". The terms that are missing would have come from the respective vanishing integral, whereas the sine terms are boundary terms that in the \"union\" would normally disappear.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "mXmWBR4pG7eO"
      },
      "outputs": [],
      "source": [
        "def computeA(h,m):\n",
        "    # ===== Input ====== #\n",
        "    # h: Spacing between nodes \n",
        "    # m: Number of internal nodes\n",
        "    # ===== Output ====== #\n",
        "    # A: Coefficient matrix A\n",
        "    \n",
        "    diag_vec = [2/3 for _ in range(m)] # node terms\n",
        "    diag_vec.insert(0,2/3) # insert left boundary term\n",
        "    diag_vec.append(2/3) # insert right boundary term\n",
        "    \n",
        "    d = np.diag( diag_vec,0 )\n",
        "    odp = np.diag( np.zeros(m+1)+1/6,1 )\n",
        "    odm = np.diag( np.zeros(m+1)+1/6,-1 )\n",
        "    A = h*(d + odp + odm)\n",
        "    return A\n",
        "\n",
        "def bk(xkm,xk,xkp,h, L = False, R = False):\n",
        "    # ===== Input ====== #\n",
        "    # xkm: x_{k-1} \n",
        "    # xk: x_{k} \n",
        "    # xkp: x_{k+1}\n",
        "    # h: Spacing between nodes\n",
        "    # endpoint: Boolean, tells you if this is an endpoint\n",
        "    # ===== Output ===== #\n",
        "    # b_k : kth element of load vector\n",
        "    \n",
        "    w = 3*pi/2\n",
        "    scale = 1/(9*h*(pi**2))\n",
        "    if R:\n",
        "        middle = 8*cos(w*xk) - 4*cos(w*xkm) + 6*pi*h*sin(w*xk)\n",
        "    elif L:\n",
        "        middle = 8*cos(w*xk) - 4*cos(w*xkp) - 6*pi*h*sin(w*xk)\n",
        "    else:\n",
        "        middle = 8*cos(w*xk) - 4*cos(w*xkm) - 4*cos(w*xkp) \n",
        "    \n",
        "    return scale*middle \n",
        "\n",
        "def make_system(mesh):\n",
        "    # ===== Input ===== #\n",
        "    # mesh: discretization list with m+2 numbers between 0 and 1\n",
        "    # ===== Output ===== #\n",
        "    # A: coefficient matrix\n",
        "    # b: load vector\n",
        "    \n",
        "    h = abs(mesh[1] - mesh[0]) # spacing\n",
        "    m = len(mesh)-2 # number of internal nodes\n",
        "    A = computeA(h,m)\n",
        "    b = [ 0 for _ in range(m+2) ] \n",
        "    \n",
        "    # compute the internal node values for bk\n",
        "    for k in range(1,m+1):\n",
        "        b[k] = bk( x[k-1], x[k], x[k+1], h )\n",
        "    \n",
        "    b[0] = bk(0, x[0], x[1],h, L = True, R = False)\n",
        "    b[-1] = bk(x[-2], x[-1], 0,h, L = False, R = True)\n",
        "    return A,np.array(b)\n",
        "\n",
        "def get_global_dof(mesh):\n",
        "    A,b = make_system(mesh)\n",
        "    Ainv = np.linalg.inv(A)\n",
        "    return Ainv@b\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPIj6Ux1G7eP"
      },
      "source": [
        "Now that we have gotten the global degrees of freedom, we can actually implement the evaluation of the polynomial. Recall that\n",
        "\n",
        "$$\n",
        "v(x) = \\sum_{i = 0}^{m+1}\\alpha_i \\phi_i(x) = \\sum_{k=0}^1 \\beta_{k,j}\\lambda_{k,j},\n",
        "$$\n",
        "\n",
        "with $\\alpha_k = \\beta_k,1 = \\beta_{k+1,0}$ for the internal nodes $k = 1,\\ldots,m$, and for the endpoints $\\alpha_0 = \\beta_1,0$, and $\\alpha_{m+1} = \\beta_{m+1,1}$. Writing this in a way that is more useful for computations we have\n",
        "\n",
        "$$\n",
        "(\\beta_{k,0}, \\beta_{k,1})=\\hat{\\beta}_k = \\begin{cases}\n",
        "(\\alpha_{k-1} , \\alpha_k), & \\text{for middle points}\\\\\n",
        "(\\alpha_{0} , 0), & \\text{left endpoint} \\\\\n",
        "(0 , \\alpha_{m+1}), & \\text{right endpoint}\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "Then we can finally implement Algorithm 9.1 (see textbook page 198)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "YYoLlniZG7eP"
      },
      "outputs": [],
      "source": [
        "def lambdak0(mesh,interval,x):\n",
        "    h = abs( mesh[1] - mesh[0] )\n",
        "    return ( mesh[interval] - x ) / h\n",
        "\n",
        "def lambdak1(mesh,interval,x):\n",
        "    h = abs( mesh[1] - mesh[0] )\n",
        "    return ( x - mesh[interval-1] ) / h\n",
        "\n",
        "def get_local_dofs(alpha, interval, M = True, L= False, R = False ):\n",
        "    \n",
        "    beta = np.zeros(2)\n",
        "    \n",
        "    if L:\n",
        "        beta[0] = alpha[0]\n",
        "    elif R:\n",
        "        beta[1] = alpha[-1]\n",
        "    else:\n",
        "        beta[0] = alpha[interval-1]\n",
        "        beta[1] = alpha[interval]\n",
        "        \n",
        "    return beta\n",
        "\n",
        "def find_interval(mesh,x):\n",
        "    h = abs(mesh[1] - mesh[0])\n",
        "    val = x/h\n",
        "    if x == mesh[0]:\n",
        "        return 1\n",
        "    elif x == mesh[-1]:\n",
        "        return len(mesh) -1\n",
        "    elif x in mesh:\n",
        "        return ceil(val)+1\n",
        "    else:\n",
        "        return ceil(val)\n",
        "\n",
        "def eval_local(mesh,interval,x):\n",
        "    vec = [ lambdak0(mesh,interval,x), lambdak1(mesh,interval,x) ]\n",
        "    return np.array(vec)\n",
        "    \n",
        "def evalpoly(alpha,mesh,x):\n",
        "    k = find_interval(mesh,x)\n",
        "    if x == mesh[0]:\n",
        "        beta = get_local_dofs(alpha,k, M = False, L = True, R = False)\n",
        "    elif x == mesh[-1]:\n",
        "        beta = get_local_dofs(alpha,k, M = False, L = False, R = True)\n",
        "    else:\n",
        "        beta = get_local_dofs(alpha,k)\n",
        "\n",
        "    lamb = eval_local(mesh,k,x)\n",
        "    return np.dot(beta,lamb)\n",
        "\n",
        "def test_func(x):\n",
        "    w = (3*pi)/2\n",
        "    return cos(w*x)\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsQLT38gVbn_"
      },
      "source": [
        "# **Results**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLwlnOzuV-Cd"
      },
      "source": [
        "We will test the data by comparing different $x$ random values, with the approximation and the exact value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "KMCWw5AhG7eQ"
      },
      "outputs": [],
      "source": [
        "x = np.linspace(0,1,num = 5)\n",
        "A,b = make_system(x)\n",
        "alpha = get_global_dof(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DL9SSQttG7eQ",
        "outputId": "6f8ffa04-4220-432b-bfbb-0535d01916cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average difference:  0.08741485072796333\n",
            "Median difference:  0.045706418122078485\n",
            "Maximum difference:  0.6777757396978094\n",
            "Minimum difference:  1.4744815242218046e-05\n"
          ]
        }
      ],
      "source": [
        "n = 10000\n",
        "xtest = np.random.rand(n)\n",
        "fexact = np.array( [evalpoly(alpha,x, t) for t in xtest] )\n",
        "ftest = np.array( [test_func(t) for t in xtest] )\n",
        "\n",
        "diff = abs(ftest - fexact)\n",
        "print( \"Average difference: \", np.average(diff) )\n",
        "print( \"Median difference: \", np.median(diff) )\n",
        "print( \"Maximum difference: \", np.max(diff) )\n",
        "print( \"Minimum difference: \", np.min(diff) )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEIqBvgwG7eR"
      },
      "source": [
        "One thing to note, is the defficiencies of my code. The code gives really good approximations everywhere except near the left endpoint. The reason for this is unknown."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3OAeTa3kG7eR",
        "outputId": "054cb4c9-b745-46aa-ad2a-a218140ba6d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Difference norm: 0.6974762266561031\n",
            "Average difference:  0.19178394034525337\n",
            "Median difference:  0.10328304087767648\n",
            "Maximum difference:  0.6780798110042228\n",
            "Minimum difference:  0.014536567106713328\n",
            "Error vector: [0.67807981 0.10328304 0.04605346 0.11696682 0.01453657]\n"
          ]
        }
      ],
      "source": [
        "approx_nodes = np.array([evalpoly(alpha,x,t) for t in x])\n",
        "exact_nodes = np.array([test_func(t) for t in x])\n",
        "diff = abs(exact_nodes-approx_nodes)\n",
        "print(\"Difference norm:\", np.linalg.norm(diff))\n",
        "print( \"Average difference: \", np.average(diff) )\n",
        "print( \"Median difference: \", np.median(diff) )\n",
        "print( \"Maximum difference: \", np.max(diff) )\n",
        "print( \"Minimum difference: \", np.min(diff) )\n",
        "print(\"Error vector:\", diff)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wj9StdA_G7eS"
      },
      "source": [
        "I am not sure on why this happens, and unfortunately did not have the time to correct it for the due date."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4GLBv0zWr7m"
      },
      "source": [
        "# **Discussion**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bcsDSoRXHZe"
      },
      "source": [
        "In this report, we covered local piecewise polynomial interpolation to linear order. The results were acceptables, regarding error, however there are still some problems that I would like to discuss.\n",
        "\n",
        "First, this code is not (yet) general, i.e. it interpolates exactly one test function. The reasoning for this is my own lack of abilities in python. The solution if of course to implement some integration scheme to compute the load vector. Unfortunately this week I had no time to implement a robust Simpson 1/3, and 3/8 method, and my lack of python knowledge, and work this week prevented me to dig into the documentation of new libraries. I have a library of numerical tools in Julia [FiscomTools.jl](https://github.com/leogabac/FiscomTools.jl) which I haven't ported to python projects (yet).\n",
        "\n",
        "I believe that next week, we will see in class some integration techniques, so I will try to make a better job in the future.\n",
        "\n",
        "The other problem, which I have no idea on why it arises, is that on the left endpoint, the approximation is considerably worse. My untested hypothesis is that I probably implemented something wrong, and need to do things more carefully.\n",
        "\n",
        "In general, I believe that the results were acceptable, but there is still a lot of room for improvement."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "leogabac_Lab4.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}