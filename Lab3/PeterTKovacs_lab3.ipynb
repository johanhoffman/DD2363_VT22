{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of PeterTKovacs_lab2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/johanhoffman/DD2363_VT22/blob/PeterTKovacs_lab3/Lab3/PeterTKovacs_lab3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RgtXlfYO_i7"
      },
      "source": [
        "# **Lab 3: iterative methods**\n",
        "**Péter Kovács**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9x_J5FVuPzbm"
      },
      "source": [
        "# **Abstract**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJipbXtnjrJZ"
      },
      "source": [
        "In this lab assignment, we venture into the broad field of iterative methods. It is clearly an understatment to write that they are quite common, since they are ubiquitous in practical computing, even for tasks that could be solved in an 'exact' way (systems of linear equations for instance).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OkT8J7uOWpT3"
      },
      "source": [
        "#**About the code**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmB2noTr1Oyo"
      },
      "source": [
        "A short statement on who is the author of the file, and if the code is distributed under a certain license. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pdll1Xc9WP0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ef03dd4f-68a4-49d9-cc5d-9d0adf151bb8"
      },
      "source": [
        "\"\"\"This program is a template for lab reports in the course\"\"\"\n",
        "\"\"\"DD2363 Methods in Scientific Computing, \"\"\"\n",
        "\"\"\"KTH Royal Institute of Technology, Stockholm, Sweden.\"\"\"\n",
        "\n",
        "# Copyright (C) 2022 Péter Kovács (ptkovacs@kth.se)\n",
        "\n",
        "# This file is part of the course DD2363 Methods in Scientific Computing\n",
        "# KTH Royal Institute of Technology, Stockholm, Sweden\n",
        "#\n",
        "# This is free software: you can redistribute it and/or modify\n",
        "# it under the terms of the GNU Lesser General Public License as published by\n",
        "# the Free Software Foundation, either version 3 of the License, or\n",
        "# (at your option) any later version.\n",
        "\n",
        "# This template is maintained by Johan Hoffman\n",
        "# Please report problems to jhoffman@kth.se"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'KTH Royal Institute of Technology, Stockholm, Sweden.'"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28xLGz8JX3Hh"
      },
      "source": [
        "# **Set up environment**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xw7VlErAX7NS"
      },
      "source": [
        "# Load neccessary modules.\n",
        "from google.colab import files\n",
        "import numpy as np\n",
        "import theano\n",
        "import theano.tensor as tt\n"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnO3lhAigLev"
      },
      "source": [
        "# **Introduction**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5zMzgPlRAF6"
      },
      "source": [
        "Just as the abstract says, we will be engaged with iterative methods in this chapter. From the simplest case of linear equations, we will proceed to the more complicated nonlinear case.\n",
        "\n",
        "A generic iterative method reads as:\n",
        "\n",
        "$x_{k+1}=g(x_k)$ where $g$ is the update function. \n",
        "\n",
        "A common example is when we aim at solving the equation $f(x)=0$. Then the choice of $g(x)=x+ \\alpha f(x)$ implies that any fixpoint of the iteration indeed solves the original equation.\n",
        "\n",
        "The convergence of the method is guaranteed - under appropriate technical conditions - by the Banach fixpoint theorem.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOQvukXZq5U5"
      },
      "source": [
        "# **Method**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1) Jacobi iteration\n",
        "\n",
        "The Jacobi iteration is used to solve systems of linear equations.\n",
        "\n",
        "Using the intrduction's notation, we would have $f(x)=\\mathbf{A}x-b$ so that the solution of the general problem is equivalent to finding the solution of the linear system of equations: $\\mathbf{A}x=b$.\n",
        "\n",
        "To improve convergence speed, a common trick is to 'precondition' the above system ie. to rather approximate the solution of $\\mathbf{AB}x=\\mathbf{B}b$ where $\\mathbf{B}$ is an arbitrary regular matrix. In the Jacobi iteration, it is chosen to be the inverse of the diagonal of $\\mathbf{A}$.\n",
        "\n",
        "Thus the update function: $g(x)=(\\mathbf{I}-\\mathbf{BA})x+\\mathbf{B}b$.\n",
        "\n",
        "To have a guarantee of convergence, we need to make sure that the update matrix has a norm less than 1.\n",
        "\n",
        "After ensuring that A is indeed regular (or rather assuming it), we would only need to check the highest singular value of the iteration matrix. But we won't check this, since the main point of iterative methods is that we use them when inverting the matrix would be too costly. So determining the largest singular value is deemed infeasible in this context as well.\n",
        "\n",
        "At the practical end of matters, we check the residual ie. how much the approximate solution changes in one step. If its norm is below a certain threshold, the iteration is terminated and we have an approximate solution. Also, the case of non-convergent iteration is intended to be detected by investigating the residual norm."
      ],
      "metadata": {
        "id": "qaCelHGGbQv8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def jacobi(A,b,tol,maxiter=10000):\n",
        "  \"\"\"\n",
        "  perform Jacobi iteration on the system defined by A and b. Iterate until the L2 norm of the residual is smaller than >>tol<< but max >>maxiter<< times\n",
        "\n",
        "  since we do not check wheter the method is convergent, I had to include manual criteria to prevent overflow: if the residual grows too much,\n",
        "  the iteration is terminated, assuming it ain't convergent\n",
        "  \"\"\"\n",
        "\n",
        "  B=np.zeros(A.shape,float)\n",
        "  \n",
        "  for i in range(A.shape[0]):\n",
        "    try:\n",
        "      B[i,i]=1./A[i,i]\n",
        "    except:\n",
        "      print('zero in diagonal, cannot apply Jacobi')\n",
        "  c=B.dot(b)\n",
        "  M=np.eye(*A.shape,0,float)-B.dot(A)\n",
        "\n",
        "  j=0\n",
        "  x=np.zeros(A.shape[0],float)\n",
        "\n",
        "  while(j<maxiter):\n",
        "\n",
        "    x_=M.dot(x)+c\n",
        "    r=x_-x\n",
        "\n",
        "    if(np.linalg.norm(r)<tol):\n",
        "      return np.diag(np.diag(x_))\n",
        "    elif(np.linalg.norm(r)>np.linalg.norm(c)*1e5): \n",
        "      print(\"suspected overflow\")\n",
        "      return -1\n",
        "    else:\n",
        "      x=x_\n",
        "      j+=1\n",
        "  return \"maxiter reached, no solution found\""
      ],
      "metadata": {
        "id": "unOAqdJ_bQhG"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "A=np.random.standard_normal((5,5))"
      ],
      "metadata": {
        "id": "_6R3MYxx0xFu"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b=np.random.standard_normal(5)"
      ],
      "metadata": {
        "id": "AnE7zryN1CRc"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=jacobi(A,b,tol=np.linalg.norm(b)/100.)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EvwllTMz1GbQ",
        "outputId": "5bfe3c9e-4905-4a7f-d540-c4c80cfcc0ee"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "suspected overflow\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A_=A+np.diag(np.diag(A))*100. # the Jacobi iteration is designed for diagonally dominated matrices"
      ],
      "metadata": {
        "id": "_ss0tNqG1f1W"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=jacobi(A_,b,tol=np.linalg.norm(b)/100.)"
      ],
      "metadata": {
        "id": "h9Zxxgxq11Og"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "higPLazc2ytQ",
        "outputId": "4ba47eb5-b81e-4523-d5d3-f69110400d7d"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.01139502,  0.00365247,  0.00046505, -0.00326163,  0.01474043])"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"norm of b: %f\\nnorm of error in Ax: %f\\nnorm of true solution y: %f\\nnorm of x-y:%f\"\n",
        "%(np.linalg.norm(b)\n",
        ",np.linalg.norm(A_.dot(x)-b)\n",
        ",np.linalg.norm(np.linalg.inv(A_).dot(b))\n",
        ",np.linalg.norm(np.linalg.inv(A_).dot(b)-x)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4RrJEkf2H0Y",
        "outputId": "a98171c4-f73c-4eac-95f2-4f16bc68d36a"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "norm of b: 1.286767\n",
            "norm of error in Ax: 0.001021\n",
            "norm of true solution y: 0.019286\n",
            "norm of x-y:0.000017\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=jacobi(A_,b,tol=np.linalg.norm(b)/10000.)"
      ],
      "metadata": {
        "id": "3A_QS5vIBXz1"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"norm of b: %f\\nnorm of error in Ax: %f\\nnorm of true solution y: %f\\nnorm of x-y:%f\"\n",
        "%(np.linalg.norm(b)\n",
        ",np.linalg.norm(A_.dot(x)-b)\n",
        ",np.linalg.norm(np.linalg.inv(A_).dot(b))\n",
        ",np.linalg.norm(np.linalg.inv(A_).dot(b)-x)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xdnmbdp0Bdwc",
        "outputId": "0c3d8739-487a-4d9e-c6d6-5d9f9d0b948f"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "norm of b: 1.286767\n",
            "norm of error in Ax: 0.000048\n",
            "norm of true solution y: 0.019286\n",
            "norm of x-y:0.000001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2) Gauss-Seidel iteration\n",
        "\n",
        "Conceptually, the Gauss-Seidel method is very similar to the Jacobi. The difference is that instead of the diagonal's inverse, we use the inverse of the lower triangular part of the original $\\mathbf{A}$ matrix.\n",
        "\n",
        "The exact details of the algorithm were taken from example 7.9."
      ],
      "metadata": {
        "id": "uvUPwkV1CwXr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def gauss_seidel(A,b,tol,maxiter=10000):\n",
        "  \"\"\"\n",
        "  perform Gauss-Seidel iteration on the system defined by A and b. Iterate until the L2 norm of the residual is smaller than >>tol<< but max >>maxiter<< times\n",
        "\n",
        "  since we do not check wheter the method is convergent, I had to include manual criteria to prevent overflow: if the residual grows too much,\n",
        "  the iteration is terminated, assuming it ain't convergent\n",
        "\n",
        "  the notation resembles the one of example 7.9 in the lecture slides\n",
        "  \"\"\"\n",
        "  \n",
        "  for i in range(A.shape[0]):\n",
        "    try:\n",
        "      _=1./A[i,i]\n",
        "    except:\n",
        "      print('zero in diagonal, cannot apply Jacobi')\n",
        "  \n",
        "  \n",
        "\n",
        "  k=0\n",
        "  x=np.zeros(A.shape[0],float)\n",
        "\n",
        "  while(k<maxiter):\n",
        "\n",
        "    x_old=x.copy()\n",
        "    \n",
        "    # update of coordinates\n",
        "    \n",
        "    for i in range(x.shape[0]):\n",
        "      x[i]=b[i]/A[i,i]\n",
        "\n",
        "      for j in range(x.shape[0]):\n",
        "        if(i==j):\n",
        "          continue\n",
        "        x[i]-=A[i,j]/A[i,i]*x[j] # due to our storage mechanism, this implementation is in fact the Gauss-Seidel\n",
        "    \n",
        "    r=x-x_old\n",
        "\n",
        "    if(np.linalg.norm(r)<tol): # found solution\n",
        "      return np.diag(np.diag(x))\n",
        "\n",
        "    elif(np.linalg.norm(r)>np.linalg.norm(b)*1e5): # suspect overflow\n",
        "      print(\"suspected overflow\")\n",
        "      return -1\n",
        "\n",
        "    else: # next iteration\n",
        "      k+=1\n",
        "\n",
        "  return \"maxiter reached, no solution found\"\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zHqKCouBe6kt"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "A=np.random.standard_normal((5,5))"
      ],
      "metadata": {
        "id": "yO5hD6wpHE67"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b=np.random.standard_normal(5)"
      ],
      "metadata": {
        "id": "E4hrB0aEHJ1M"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=gauss_seidel(A,b,tol=np.linalg.norm(b)/100.)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fz4TfywHPJU",
        "outputId": "e752a195-efc9-4c39-b51a-661a9921d32b"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "suspected overflow\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "conjecture: the Gauss-Seidel works best for almost lower-triangular matrices"
      ],
      "metadata": {
        "id": "0vcoXloUHuSx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "A_=A.copy()\n",
        "for i in range(A.shape[0]):\n",
        "  for j in range(i):\n",
        "    A_[j,i]=A_[i,j]/1000.\n"
      ],
      "metadata": {
        "id": "3e1Cw6gQHTck"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=gauss_seidel(A_,b,tol=np.linalg.norm(b)/100.)"
      ],
      "metadata": {
        "id": "1Ai9tXmbIMnX"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"norm of b: %f\\nnorm of error in Ax: %f\\nnorm of true solution y: %f\\nnorm of x-y:%f\"\n",
        "%(np.linalg.norm(b)\n",
        ",np.linalg.norm(A_.dot(x)-b)\n",
        ",np.linalg.norm(np.linalg.inv(A_).dot(b))\n",
        ",np.linalg.norm(np.linalg.inv(A_).dot(b)-x)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9qbXTO0IvB1",
        "outputId": "90ac64f4-9318-498b-b143-26258b6402f8"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "norm of b: 3.596355\n",
            "norm of error in Ax: 0.000032\n",
            "norm of true solution y: 3129.866443\n",
            "norm of x-y:0.005133\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=gauss_seidel(A_,b,tol=np.linalg.norm(b)/10000.)"
      ],
      "metadata": {
        "id": "92NFcnK8I3cu"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"norm of b: %f\\nnorm of error in Ax: %f\\nnorm of true solution y: %f\\nnorm of x-y:%f\"\n",
        "%(np.linalg.norm(b)\n",
        ",np.linalg.norm(A_.dot(x)-b)\n",
        ",np.linalg.norm(np.linalg.inv(A_).dot(b))\n",
        ",np.linalg.norm(np.linalg.inv(A_).dot(b)-x)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PC22-MXUI78y",
        "outputId": "575f5760-f4c7-4993-a6eb-40fd0e2b1070"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "norm of b: 3.596355\n",
            "norm of error in Ax: 0.000000\n",
            "norm of true solution y: 3129.866443\n",
            "norm of x-y:0.000037\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3) Newton method for scalar functions\n",
        "\n",
        "The Newton method is a fairly simple algorithm for approximating the solution of the nonlinear scalar equation $f(x)=0$.\n",
        "\n",
        "The update rule is: $x_{k+1}=x_{k}-f(x_k)/f'(x_k)$\n",
        "\n",
        "It is easy to see that the method is based on the first order approximation of the function around the current $x$ point.\n",
        "\n",
        "In general, the computation of the derivative is a nontrivial problem by itself. To solve this (well, rather to limit the amount of work that is needed) we will compute symbolic derivatives with the **theano** package. "
      ],
      "metadata": {
        "id": "loPYEIh6Mt-u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def newton_solver(f,df,x_0,tol,maxiter=10000):\n",
        "  '''\n",
        "  Newton  solver for f(x)=0, assuming that f,df are functions for f and its derivative\n",
        "\n",
        "  stopping criterion: |f(x)|<tol\n",
        "  '''\n",
        "\n",
        "  x=x_0\n",
        "  i=0\n",
        "\n",
        "  while(i<maxiter):\n",
        "\n",
        "    if(np.abs(f(x))<tol):\n",
        "      return x\n",
        "\n",
        "    try:\n",
        "      x=x-f(x)/df(x)\n",
        "    except:\n",
        "      print(\"division by zero?\")\n",
        "      return -1\n",
        "\n",
        "    i+=1\n",
        "  \n",
        "  print(\"maxiter reached, no soltion found\")\n",
        "  return -1\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3XlntQ9KvXIG"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xx=tt.dscalar()\n",
        "yy=xx**3-2*xx**2+10*np.sin(xx)**2\n",
        "dyy=tt.grad(yy,xx)\n",
        "\n",
        "f=theano.function([xx],yy)\n",
        "df=theano.function([xx],dyy)"
      ],
      "metadata": {
        "id": "JhrezTiK0PJ1"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_s=newton_solver(f,df,10.,1e-2)"
      ],
      "metadata": {
        "id": "FUInI4ayba1c"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f(x_s)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mEC-xa-LmMTJ",
        "outputId": "3df9ef34-a20d-4a42-af50-c9d275bf7c6e"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(0.00560625)"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_s # 0 is actually solution"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5skt-mfmOCr",
        "outputId": "a76f5de2-48c1-4143-f291-3754612d5820"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.02643249272291941"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 4) Newton method for vector equations\n",
        "\n",
        "The Newton method for vector equations is to solve the nonlinear vector equation 𝑓(𝑥)=0. In spirit, it is the straightorward generalizaion of the scalar method.\n",
        "\n",
        "The update rule is: $x_{k+1}=x_k-(f'(x_k))^{-1}f(x_k)$\n",
        "\n",
        "It is easy to see that the method is based on the first order approximation of the function around the current 𝑥 point as well.\n",
        "\n",
        "For the Jacobian, we again rely on theano.\n"
      ],
      "metadata": {
        "id": "tItUbf3MOP6P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def newton_vector_solver(f,df,x_0,tol,maxiter=10000):\n",
        "  '''\n",
        "  Newton  solver for f(x)=0, assuming that f,df are functions for f and its Jacobian\n",
        "\n",
        "  stopping criterion: |f(x)|<tol\n",
        "  '''\n",
        "\n",
        "  x=x_0\n",
        "  i=0\n",
        "\n",
        "  while(i<maxiter):\n",
        "\n",
        "    if(np.linalg.norm(f(x))<tol):\n",
        "      return x\n",
        "\n",
        "    try:\n",
        "      x=x-np.linalg.inv(df(x)).dot(f(x))\n",
        "    except:\n",
        "      print(\"singular Jacobian?\")\n",
        "      return -1\n",
        "    i+=1\n",
        "  \n",
        "  print(\"maxiter reached, no soltion found\")\n",
        "  return -1\n",
        "\n"
      ],
      "metadata": {
        "id": "4q4sgnU548e6"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=tt.dvector('x')\n",
        "             \n",
        "y=x*(1+x.sum()-x**2)\n",
        "dy=theano.gradient.jacobian(y,x)\n",
        "\n",
        "f=theano.function([x],y)\n",
        "df=theano.function([x],dy)"
      ],
      "metadata": {
        "id": "7YLr3S40ZGHr"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_s=newton_vector_solver(f,df,[10.,10.],1e-2)"
      ],
      "metadata": {
        "id": "5cHQ9fM9aVap"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_s"
      ],
      "metadata": {
        "id": "fFgEzDV57XUM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71f1130c-59a0-4dd2-f28e-49a0ae4ac8e6"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2.41428556, 2.41428556])"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.linalg.norm(x_s-np.asarray([1+np.sqrt(2),1+np.sqrt(2)])) # the latter is actually a solution"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XsEcz_3tlxNv",
        "outputId": "bcf48a1c-d138-4ba3-f7d0-e402d8e2be7e"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0001018251269741721"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.linalg.norm(f(x_s)) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUKRx3N5mECH",
        "outputId": "5c7bf3d9-4e15-4467-debb-7a4235e3b9fc"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0006953438961424595"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsQLT38gVbn_"
      },
      "source": [
        "\n",
        "# **Summary, discussion**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLwlnOzuV-Cd"
      },
      "source": [
        "Based on the tests, we can conclude that all our methods work.\n",
        "\n",
        "For the iterative methods, an extra layer of security had to be added to ensure that iterating with matrices that won't lead to convergence will not lead to overflow.\n",
        "\n",
        "The Newton methods both worked well, despite the attempt to test on nontrivial functions. To compute symbolic derivatives, the **theano** is employed."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "G6dWmBvRnGYm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}