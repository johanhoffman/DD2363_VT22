{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/johanhoffman/DD2363_VT22/blob/leogabac-Lab3/Lab3/leogabac_Lab3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RgtXlfYO_i7"
      },
      "source": [
        "# **Lab 3: Iterative Methods**\n",
        "**Leonardo Gabriel Alanis Cant√∫**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9x_J5FVuPzbm"
      },
      "source": [
        "# **Abstract**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6UFTSzW7P8kL"
      },
      "source": [
        "Exact methods are really useful whenever they work, until they do not. Sometimes when dealing with massive amount of data, or really complex systems, considering the accuracy/performance ratio, it is better to deal with approximate solutions. Additionally, iterative methods help us to develop methods for those type of problems for which the solution cannot be computed exactly, an example of this is non-linear dynamics.\n",
        "In this report, we will look at two approximation methods for systems of linear equations, the Jacobi approximation method and the Gauss-Seidel method. Additionally, we look at one of the most famous methods for root finding in one variable: the Newton's method in one variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "Pdll1Xc9WP0e",
        "outputId": "9e782dc7-4ad0-48f9-d45c-2200e83dec4d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'KTH Royal Institute of Technology, Stockholm, Sweden.'"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"This program is a template for lab reports in the course\"\"\"\n",
        "\"\"\"DD2363 Methods in Scientific Computing, \"\"\"\n",
        "\"\"\"KTH Royal Institute of Technology, Stockholm, Sweden.\"\"\"\n",
        "\n",
        "# Copyright (C) 2020 Johan Hoffman (jhoffman@kth.se)\n",
        "\n",
        "# This file is part of the course DD2365 Advanced Computation in Fluid Mechanics\n",
        "# KTH Royal Institute of Technology, Stockholm, Sweden\n",
        "#\n",
        "# This is free software: you can redistribute it and/or modify\n",
        "# it under the terms of the GNU Lesser General Public License as published by\n",
        "# the Free Software Foundation, either version 3 of the License, or\n",
        "# (at your option) any later version.\n",
        "\n",
        "# This template is maintained by Johan Hoffman\n",
        "# Please report problems to jhoffman@kth.se"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28xLGz8JX3Hh"
      },
      "source": [
        "# **Set up environment**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xw7VlErAX7NS"
      },
      "outputs": [],
      "source": [
        "# Load neccessary modules.\n",
        "#from google.colab import files\n",
        "\n",
        "import time\n",
        "import numpy as np\n",
        "import math\n",
        "import scipy as sp\n",
        "from scipy import special\n",
        "\n",
        "#try:\n",
        "#    from dolfin import *; from mshr import *\n",
        "#except ImportError as e:\n",
        "#    !apt-get install -y -qq software-properties-common \n",
        "#    !add-apt-repository -y ppa:fenics-packages/fenics\n",
        "#    !apt-get update -qq\n",
        "#    !apt install -y --no-install-recommends fenics\n",
        "#    from dolfin import *; from mshr import *\n",
        "    \n",
        "#import dolfin.common.plotting as fenicsplot\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib import tri\n",
        "from matplotlib import axes\n",
        "from mpl_toolkits.mplot3d import Axes3D"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnO3lhAigLev"
      },
      "source": [
        "# **Introduction**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5zMzgPlRAF6"
      },
      "source": [
        "The _fixed point iteration_ methods are based on the following ansatz\n",
        "\n",
        "$$\n",
        "x^{(k+1)} = g(x^{(k)}),\n",
        "$$\n",
        "\n",
        "one of the easiest form is to assume a linear function, this is called _stationary iterative methods_\n",
        "\n",
        "$$\n",
        "x^{(k+1)} = Mx^{(k)} + c.\n",
        "$$\n",
        "\n",
        "When solving a system of linear equations $Ax = b$, if we consider the splitting\n",
        "\n",
        "$$\n",
        "A = \\text{diag}(A) + \\text{the rest}  =D + (A-D),\n",
        "$$\n",
        "\n",
        "and the iteration matrix, and vector\n",
        "\n",
        "$$\n",
        "M = (I - D^{-1}A), \\quad c = D^{-1}b.\n",
        "$$\n",
        "\n",
        "Componen wise, the Jacobi iteration takes the form\n",
        "\n",
        "$$\n",
        "x_{i}^{(k+1)}=a_{i i}^{-1}\\left(b_{i}-\\sum_{j \\neq i} a_{i j} x_{j}^{(k)}\\right), \\quad \\forall i\n",
        "$$\n",
        "\n",
        "This method converges if $\\| I -D^{-1}A \\| < 1 $. The _Gauss-Seidel method_ is based on another fixed-point iteration with splitting\n",
        "\n",
        "$$\n",
        "A = L + (A-L),\n",
        "$$\n",
        "\n",
        "with the following iteration matrix and vector\n",
        "\n",
        "$$\n",
        "M_{G S}=-L^{-1}(A-L)=\\left(I-L^{-1} A\\right), \\quad L^{-1}b,\n",
        "$$\n",
        "\n",
        "which in component wise form lets us have the form\n",
        "\n",
        "$$\n",
        "x_{i}^{(k+1)}=a_{i i}^{-1}\\left(b_{i}-\\sum_{j<i} a_{i j} x_{j}^{(k+1)}-\\sum_{j>i} a_{i j} x_{j}^{(k)}\\right), \\quad \\forall i .\n",
        "$$\n",
        "With convergence criterion $\\| I -L^{-1}A \\| < 1 $\n",
        "\n",
        "Newton's method tries to solve the equation $f(x) = 0$ by Taylor expanding around the  $k$-th iteration\n",
        "\n",
        "$$\n",
        "0 = f(x) = f(x^{(k)}) + f'(x^{(k)})(x-x^{(k)}) + \\cdots,\n",
        "$$\n",
        "\n",
        "and by isolating, we get\n",
        "\n",
        "$$\n",
        "x^{(k+1)} = x^{(k)} - [f'(x^{(k)})]^{-1}f(x^{(k)})\n",
        "$$\n",
        "\n",
        "Note that the method requires to evaluate the first derivative at a point. Ideally, we will not be provided with the derivative, and we want to compute everything numerically, hence a forward differenciation scheme will be implemented.\n",
        "\n",
        "$$\n",
        "f'(x) \\approx \\dfrac{f(x+h) - f(x)}{h}\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOQvukXZq5U5"
      },
      "source": [
        "# **Method**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AIyaCMdqaDRm"
      },
      "source": [
        "Jacobi iteration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U2ANBSyCaDRm"
      },
      "outputs": [],
      "source": [
        "def jacobi_iteration(A,b,iter = 100):\n",
        "    # ===== Input ===== #\n",
        "    # A: n x n matrix non-singular matrix\n",
        "    # b: n-vector\n",
        "    # ===== Output ===== #\n",
        "    # x: n-vector solution to Ax = b\n",
        "    \n",
        "    assert A.shape[0] == A.shape[1], \"Not square matrix\"\n",
        "    assert A.shape[0] == len(b), \"A and b Dimension mismatch\"\n",
        "    \n",
        "    n = A.shape[0]\n",
        "    x = np.zeros(n)\n",
        "    xnew = np.zeros(n)\n",
        "    \n",
        "    for _ in range(iter):\n",
        "        for i in range(n):\n",
        "            s = sum([ A[i,j]*x[j] for j in range(n) if j!=i]) # A neat one-liner\n",
        "            xnew[i] = (1/A[i,i])*(b[i] - s)\n",
        "        x = np.copy(xnew)\n",
        "    \n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7m7XM5VaDRn"
      },
      "source": [
        "Gauss-Seidel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iqzg8_21aDRn"
      },
      "outputs": [],
      "source": [
        "def gauss_seidel(A,x,iter = 100):\n",
        "    # ===== Input ===== #\n",
        "    # A: n x n matrix non-singular matrix\n",
        "    # b: n-vector\n",
        "    # ===== Output ===== #\n",
        "    # x: n-vector solution to Ax = b\n",
        "    \n",
        "    assert A.shape[0] == A.shape[1], \"Not square matrix\"\n",
        "    assert A.shape[0] == len(b), \"A and b Dimension mismatch\"\n",
        "    \n",
        "    n = A.shape[0]\n",
        "    x = np.zeros(n)\n",
        "    xnew = np.zeros(n)\n",
        "    \n",
        "    for _ in range(iter):\n",
        "        for i in range(n):\n",
        "            s1 = sum([ A[i,j]*xnew[j] for j in range(i)])\n",
        "            s2 = sum([ A[i,j]*x[j] for j in range(i+1,n)])\n",
        "            xnew[i] = (1/A[i,i])*( b[i] - s1 - s2)\n",
        "    \n",
        "        x = np.copy(xnew)\n",
        "    return x\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqUvhogbaDRn"
      },
      "source": [
        "Newton's Method for roots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sHdJn9DQaDRn"
      },
      "outputs": [],
      "source": [
        "def forward_diff(f,x,h):\n",
        "    df = f(x+h)-f(x)\n",
        "    return df/h\n",
        "\n",
        "def newton_univar(f,x0,h = 0.01,iter = 10):\n",
        "    \n",
        "    # ===== Input ===== #\n",
        "    # f: A function for which we want to compute its roots\n",
        "    # x0: An initial guess of the root\n",
        "    # h: The step size to use in the differentiation process\n",
        "    # ===== Output ===== #\n",
        "    # x: Approximate root of the function\n",
        "    \n",
        "    x = x0 # initialize\n",
        "    \n",
        "    for _ in range(iter):\n",
        "        df = forward_diff(f,x,h)\n",
        "        x -= f(x)/df\n",
        "    return x    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsQLT38gVbn_"
      },
      "source": [
        "# **Results**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLwlnOzuV-Cd"
      },
      "source": [
        "We will test the Jacobi iteration method and Gauss-Seidel with the same two systems of equations, using only 5 iterations for each, so that we can compare accuracy between the two methods. If we were to compare with lots of iterations, there would not be too much room to compare, since they are expected to converge eventually.\n",
        "\n",
        "Additionally, we will compare the residual error with the exact solutions obtained by Wolfram Mathematica.\n",
        "\n",
        "For the Jacobi method:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "unJS41D0aDRp",
        "outputId": "4aaadf82-feb1-4b84-b3e2-31d84e1f22e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "|Ax - b| = 0.19982519370867116\n",
            "|x - y| = 0.010491991240013399\n"
          ]
        }
      ],
      "source": [
        "A = np.array([[9,2,3], [1,12,9], [4,6,14] ] )\n",
        "b = np.array([7,2,1])\n",
        "y = np.array([95/118,19/59,-35/118])\n",
        "x = jacobi_iteration(A,b,iter = 5)\n",
        "print(\"|Ax - b| =\",np.linalg.norm(A@x - b) )\n",
        "print(\"|x - y| =\",np.linalg.norm(x - y) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G_N1X5GwaDRq",
        "outputId": "7512b45f-e306-43f1-cee1-f6e65e366ac9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "|Ax - b| = 0.27185263832472084\n",
            "|x - y| = 0.04058281331966143\n"
          ]
        }
      ],
      "source": [
        "A = np.array([[5,-1,2], [3,8,-2], [1,1,4] ] )\n",
        "b = np.array([12,-25,6])\n",
        "y = np.array([1,-3,2])\n",
        "x = jacobi_iteration(A,b,iter = 5)\n",
        "print(\"|Ax - b| =\",np.linalg.norm(A@x - b) )\n",
        "print(\"|x - y| =\",np.linalg.norm(x - y) )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2IA3dybqaDRr"
      },
      "source": [
        "Whereas for the Gauss-Seidel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TQ_4t1mAaDRr",
        "outputId": "bc469428-c4e2-4775-d774-16008e77b046"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "|Ax - b| = 0.013255355864182633\n",
            "|x - y| = 0.001602593491056047\n"
          ]
        }
      ],
      "source": [
        "A = np.array([[9,2,3], [1,12,9], [4,6,14] ] )\n",
        "b = np.array([7,2,1])\n",
        "y = np.array([95/118,19/59,-35/118])\n",
        "x = gauss_seidel(A,b, iter = 5)\n",
        "print(\"|Ax - b| =\",np.linalg.norm(A@x - b) )\n",
        "print(\"|x - y| =\",np.linalg.norm(x - y) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OWOs6ulFaDRs",
        "outputId": "5b8a8117-32ed-48c4-e7ef-4c723823e016"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "|Ax - b| = 0.0008591570135093311\n",
            "|x - y| = 0.000132606324258134\n"
          ]
        }
      ],
      "source": [
        "A = np.array([[5,-1,2], [3,8,-2], [1,1,4] ] )\n",
        "b = np.array([12,-25,6])\n",
        "y = np.array([1,-3,2])\n",
        "x = gauss_seidel(A,b, iter= 5)\n",
        "print(\"|Ax - b| =\",np.linalg.norm(A@x - b) )\n",
        "print(\"|x - y| =\",np.linalg.norm(x - y) )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_aOJMl9aDRt"
      },
      "source": [
        "For the Newton method, we will try to compute the 3rd zero of the Bessel function of the first kind of order zero. This is because I wanted to try a special function for which it is not possible to compute the zero by hand. The really well approxmated answer is $x \\approx 2.4048$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3v8S6hGyaDRt",
        "outputId": "076aeb88-15a0-4836-dce3-ae67946969da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "f(x) = -1.0239231817845196e-16\n",
            "Relative error: 1.062778433676799e-05\n"
          ]
        }
      ],
      "source": [
        "def foo(x):\n",
        "    return sp.special.jv(0,x)\n",
        "\n",
        "z = newton_univar(foo,3)\n",
        "error = abs(z-2.4048)/2.4048\n",
        "print(\"f(x) =\",foo(z))\n",
        "print(\"Relative error:\",error)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4GLBv0zWr7m"
      },
      "source": [
        "# **Discussion**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bcsDSoRXHZe"
      },
      "source": [
        "To summarize, we built some algorithms that approximate solutions for linear systems of equations: the Jacobi and Gauss-Seidel method. It was astonishing to see that for systems for which they can be used, they converge really quickly, specially the Gauss-Seidel method, its convergence rate really impressed me. \n",
        "\n",
        "Personally, I usually do not consider approximate methods when dealing with linear systems, since I used to think \"What is the point if I can get the exact solution, up to floating-point errors\"; however, after this report, I will consider these methods when dealing with huge linear systems for which the exact methods become computationally intensive. I belive that by using the Julia language, these methods could be promising for numerical computations, and really high performance. This could be done by using parallelization and generic type-stable code.\n",
        "\n",
        "The Newton's method for roots works as good as expected, even for special functions. One thing that could be done better is the differentiation process, here we used the most basic, but there are more complicated schemes that give better approximations with a higher step-size."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "leogabac_Lab3.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}